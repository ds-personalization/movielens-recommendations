{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are placing ourselves in the position of the owners of a movie streaming platform, akin to Netflix, Hulu, Showtime and the like.\n",
    "\n",
    "We are going to **recommend movies to users this streaming platform** that have already rated at least one movie.\n",
    "\n",
    "Our full dataset can be found here: [Full Movielens Dataset](https://grouplens.org/datasets/movielens/ )\n",
    "\n",
    "We wish to focus on a particular business objective : **recommend ten movies to users that have already watched at least two movies on the platform**. Those users can be seen as valuable customers that are more likely to keep watching movies, especially if recommendations are relevant and, more importantly, are perceived as relevant by the user. Therefore we feel it is important to keep those users' business and enhance their experience with great recommendation to keep their interest up.\n",
    "\n",
    "Therefore our work attempts at providing solutions to customer retention problems and does not address the cold start problem. \n",
    "\n",
    "To gain practical intuition for how some models work, and to develop methods to test and explore them, we will greatly **reduce the original data** (~ 27 M ratings) to  ~ 1 M ratings (from 130,000 users and 22,000 movies). \n",
    "\n",
    "#### What recommendation engines do we implement? \n",
    "\n",
    "Our core models use **multi-entity representation in matrix factorization**. We will explain the choices we made and define the models more precisely in our analysis. We compared results to two **benchmarks**: the least complex is a simple baseline model predicting ratings based on **item and user biases** and the second is a **vanilla matrix factorization**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Exploring the data](#1)\n",
    "2. [Defining the models](#2)\n",
    "    1. [Baseline models](#21)\n",
    "    2. [Multi-entity matrix factorization (MEMF) models](#22)\n",
    "        1. [Genre-based model](#221)\n",
    "        2. [Collaborative filtering models](#222)\n",
    "3. [Exploring the models](#3)\n",
    "4. [Testing the models](#4)\n",
    "    1. [Accuracy](#41)\n",
    "    2. [Diversity](#42)\n",
    "    3. [Coverage](#43)\n",
    "5. [Extending the models](#5)\n",
    "6. [Conclusion](#6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "## Exploring the data\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before introducing our models, let us explore the data and extract useful statistics from them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "from lib import preprocessing\n",
    "from lib import utils\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize random state\n",
    "random_state = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample the data\n",
    "data = preprocessing.sample_data(\"ratings.csv\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>185990</td>\n",
       "      <td>134853</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>190879</td>\n",
       "      <td>26462</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106328</td>\n",
       "      <td>1635</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60315</td>\n",
       "      <td>4401</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90703</td>\n",
       "      <td>1273</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user    item  rating\n",
       "0  185990  134853     0.5\n",
       "1  190879   26462     4.0\n",
       "2  106328    1635     2.5\n",
       "3   60315    4401     4.0\n",
       "4   90703    1273     5.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# peek at the first lines\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1041232"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the total number of ratings\n",
    "tot_ratings = utils.total_ratings(data)\n",
    "tot_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130138"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the number of users\n",
    "tot_users = utils.unique_users(data)\n",
    "tot_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22243"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the number of items\n",
    "tot_items = utils.unique_movies(data)\n",
    "tot_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17091856337119057"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute an index of how wide the matrix is\n",
    "width_index = utils.shape_matrix_index(data)\n",
    "width_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9996402920662102"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the sparsity of the matrix\n",
    "sparsity = utils.sparsity_index(data)\n",
    "sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x105c9d710>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the distribution of number of ratings per item\n",
    "%matplotlib inline\n",
    "ratings_per_item = preprocessing.count_ratings(data, \"item\")\n",
    "ratings_per_item.hist(bins = [i for i in range(0,100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a18468ac8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the distribution of number of ratings per user\n",
    "ratings_per_user = preprocessing.count_ratings(data, \"user\")\n",
    "ratings_per_user.hist(bins = [i for i in range(0,60)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TODO : COMMENTER LES COURBES*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "## Defining the models\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose to build models based on multi-entity representation in matrix factorization. Let us define our models more precisely as well as the two benchmarks used for comparison while testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='21'></a>\n",
    "### Baseline models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User and item bias (B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TODO : DEFINIR LE MODELE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix factorization (MF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TODO : DEFINIR LE MODELE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='22'></a>\n",
    "### Multi-entity matrix factorization (MEMF) models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to predict movie ratings for users and recommend appropriate movies, we felt we could leverage the advantages of matrix factorization - mainly its simplicity and the linear complexity that makes it a great starting point to recommend from large datasets. We felt that splitting user vectors on different clusters of movies would provide better result than vanilla matrix factorization. \n",
    "\n",
    "To illustrate this intuition, let us consider the case in which a user has rated 2 movies m1 and m2. m1 is a Christmas romantic-comedy and m2 is a documentary on the Vietnam War. We want to predict the user's rating for movie m3, another Christmas romantic-comedy. In this case we don't believe the rating of m2 should have a significant impact of our predicted rating for m3. Of course, this is a fairly simplistic view of the problem, real-world data demonstrates much more complex dynamics between ratings and movies, and such an example in context would be harder to assess.\n",
    "\n",
    "Just as recommender systems such as Spotify's divide user tastes in clusters akin to genres, we will **split user vectors on different movie clusters**, predict values on each cluster separately, and weigh the predictions according to a movie's \"membership\" to a cluster (quantifying a movie's membership to a cluster using its distance to different centroids).\n",
    "\n",
    "Now the question is: **how do we construct movie clusters**? \n",
    "\n",
    "We divided our MEMF models in two categories based on how such clusters were constructed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='221'></a>\n",
    "#### Genre-based model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TODO : DEFINIR LE MODELE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='221'></a>\n",
    "#### Collaborative filtering models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "\n",
    "This set of models was based on initial **k-means clustering of movies based on their vector representations in the ratings matrix**. This corresponds to the first phase of an item-based neighborhood models in which each item is assigned a number of closest neighbors used to predict its ratings.\n",
    "\n",
    "The following three models differ in how they use this initial clustering both in the fitting procedures to the training data and in the prediction phase. In order of increasing complexity:\n",
    "\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***K-means MEMF with one cluster per movie (K-means-MEMF-1)***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is the most basic of the three and acts as a cluster-based baseline for the other two. After the initial k-means clustering of movies, it records each movie's cluster (one and only one for each movie). It then takes the training data and trains **one Matrix Factorization (with item and movie biases and L2 regularization) model for each cluster keeping only the movies belonging to that cluster**. Predictions for a given pair `(u,i)` where `u` is a user, and `i` a movie, are made by looking up `i`'s cluster and retrieving the associated model. The output prediction is that model's prediction.\n",
    "\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***K-means MEMF with one main cluster per movie and weighted biases (K-means-MEMF-2)***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This second model accounts for the **quantification of cluster membership of movies to more than one cluster in the prediction phase only**.\n",
    "\n",
    "After the initial k-means clustering of movies, weights quantifying how far a movie is to its closest `k'` clusters (`k' <= k`) are computed using cosine similarity and stored. The weights are obtained by selecting the `k'` closest clusters, dividing the distance to each of these clusters by the largest distance - if not too small, in which case we consider that all of the `k'` contribute equally to the movie and we assign the same weights to all -, calculating the exponential of the opposite of those divided distances and normalizing. The exact formula for weights of an item $i$ regarding its membership to different clusters is:\n",
    "\n",
    "$\\forall l \\in C_{k'}(i) \\; \\; \\; \\; w(i,l) = \\frac{e^{-\\lambda \\frac{dist(i,l)}{dist(i,l^{*})}}}{\\sum_{l' \\in C_{k'}(i)}e^{-\\lambda \\frac{dist(i,l')}{dist(i,l^{*})}}} \\; \\; \\; \\; \\; \\; \\; \\; \\; \\; \\; \\; \\; \\; \\; \\; (1)$\n",
    "\n",
    "where $C_{k'}(i)$ is the set of the $k'$ closest clusters to i, $\\lambda$ is a free parameter to choose with cross-validation or another model selection method and $l^{*} = argmax(dist(i,l))$\n",
    "\n",
    "We also keep track of the closest (one and only one) cluster to each item.\n",
    "\n",
    "After those membership weights have been computed for all items, we move on to train one Matrix Factorization (with item and movie biases and L2 regularization) model for each cluster keeping only the movies closest to that cluster, just as we did in the previous model. This means that **each movie's ratings will only be in the training data for one and only one MF model**.\n",
    "\n",
    "Predictions for a given pair `(u,i)` where `u` is a user, and `i` a movie, are made by looking up `i`'s main cluster (the closest one) and retrieving the associated model. We proceed to make a prediction for the pair using this model. Then we retrieve the biases (user only, since the item hasn't been seen by the other models) from the models corresponding to `i`'s other closest clusters and our final prediction is weighted sum of 1) the prediction from the main cluster model and 2) the user `u` biases associated with the other closest clusters for `i`. More precisely, for the pair `(u,i)`, using previous notations:\n",
    "\n",
    "$pred(u,i) = w(i,l^{*}(i))pred_{model_{l^{*}(i)}}(u,i) + \\sum_{l \\in C_{k'}(i)\\setminus l^{*}(i)}{w(i,l)(mean\\_ratings(l) + bias(u,l))}$\n",
    "\n",
    "where $l^{*}(i)$ is the closest cluster to item $i$, $mean\\_ratings(l)$ if the global means of the training matrix for the model associated with cluster $l$ and $bias(u,l)$ is the user bias extracted from this fitted model.\n",
    "\n",
    "The idea behind this procedure is **the incorporation of more information on the item to the prediction through weighted biases translating the user's affinity to the movie's secondary clusters**.\n",
    "\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***K-means MEMF with weighted predictions (K-means-MEMF-3)***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This third and most complex model allows for a movie to belong to more than one cluster during the training phase. Like in the previous model, after the initial k-means phase, the `k'` closest clusters for each item are computed and the associated weights as well as in (1).\n",
    "\n",
    "This time, in the training phase, item $i$ is passed to each cluster's model for its `k'` closest clusters. **Each movie's ratings will be in the training data for `k'` MF models**.\n",
    "\n",
    "Predictions for a given pair `(u,i)` where `u` is a user, and `i` a movie are made using a weighted sum of predictions from its of its `k'` closest clusters' models. Using previous notation, it writes as:\n",
    "\n",
    "$pred(u,i) = \\sum_{l \\in C_{k'}(i)}{w(i,l)pred_{model_{l}}(u,i)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the difficulty is finding values for `k'` that give the best results. We suspect an optimal `k'` should be quite small, as adding information on membership of more than a few clusters is likely to add more noise than meaningful information.\n",
    "\n",
    "For instance let us consider a case in which the clusters correspond roughly to three genres: comedy, romance and documentary. Choosing `k' = 3` means that when predicting ratings for a rom-com means that we will also consider ratings from the documentary genre. We are not convinced that doing so would improve results and on the contrary, it is probable that it would be more harmful to predictions than anything else."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "## Exploring the models\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose hyperparameters for all models by separating the training data into proper training and validation sets and evaluating the RMSE. We were limited in terms of computational power so we ended up probably choosing sub-optimal parameters due to a lack of exploration of the parameters' space.\n",
    "\n",
    "We chose to see how our models perform on specific segments that are relevant to our business problem: since we want to recommend movies in the optic of customer retention, rather than to get new customers as a primary objective, we are interested to see how well our models perform on users with many ratings and both on the most popular movies and scarcely rated movies - that could provide great ways to add diversity to the predictions.\n",
    "\n",
    "The following notebooks contain fitting and exploration of the models and associated conclusions:\n",
    "\n",
    "* `.ipynb` *TODO : METTRE LE NOM DU FICHIER d'EXPLORATION DE TON MODELE*\n",
    "* `K-means-MEMF-exploration.ipynb` \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "## Testing the models\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we report our testing results. Keeping our business objective in mind we evaluated the models on 3 criteria:\n",
    "* Accuracy\n",
    "* Diversity\n",
    "* Catalog coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='41'></a>\n",
    "### Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used two accuracy metrics: **RMSE** and **Normalized Discounted Cumulative Gain (NDCG)**.\n",
    "\n",
    "RMSE is a common metric used in literature to compare recommender systems offline. The RMSE is in units of ratings rather than in units of squared ratings like the MSE - which makes it more interpretable than the MSE. The RMSE tends to disproportionately penalize large errors because of the squared term within the summation. As we wish to recommend films using a top-k approach, such a penalization is not a problem and should be encouraged to keep the predicted order of movies (in terms of ratings) for a user close to the ground-truth ratings. On the other hand, small differences between predicted and actual ratings are not a problem as long as they are not large enough to distort the recommendation order. It also aligns nicely with the evaluation of matrix factorization which essentially attempts to reduce the MSE of the ratings matrix and the generated latent factor matrices. \n",
    "\n",
    "*TODO : DEFINIR LE NDCG UN PEU, COMMENTER POURQUOI C'EST UTILE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table summarizes the RMSE score on the testing set for the different models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Models | RMSE |\n",
    "|:----:|:----:|\n",
    "|Baseline|0.9828|\n",
    "|Matrix Factorization|0.9535|\n",
    "|Genre-based MEMF|0.9691|\n",
    "|K-means-MEMF-1|0.9432|\n",
    "|K-means-MEMF-2|0.9493|\n",
    "|K-means-MEMF-3|0.9186|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All models perform significantly better than the baseline and all k-means based models perform better than their counterparts**. There is an improvement of more than 0.06 between the RMSE of the baseline and the best k-means model. Genre-based MEMF's accuracy is lower than Matrix Factorization over the whole data, suggesting that manually tagged genres do not provide an easily exploitable structure for the movies in the dataset and that is not worth incorporating this model when extending our final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NDCG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TODO : FAIRE PAREIL QUE POUR RMSE AVEC UN TABLEAU RECAPITULATIF + COMMENTAIRES*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='42'></a>\n",
    "### Diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TODO : DEFINIR LA MESURE QUE T'AS IMPLEMENTE ET L'IDEE DERRIERE*\n",
    "\n",
    "*TODO : REPORT LES RESULTATS ET COMMENTE LES*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='43'></a>\n",
    "### Coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sparsity of ratings matrices can lead to a certain proportion of the items never or hardly ever being recommended; not as a result of a poor affinity with all users or an intrinsic poor quality of the item, but more as an artefact of the lack of ratings in the matrix.\n",
    "\n",
    "We have computed catalog coverage across the different algorithms - which can be seen as another way to evaluate diversity of the recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Models | Coverage |\n",
    "|:----:|:----:|\n",
    "|Baseline|0.3990|\n",
    "|Matrix Factorization|0.4012|\n",
    "|Genre-based MEMF|0.4009|\n",
    "|K-means-MEMF-1|0.4027|\n",
    "|K-means-MEMF-2|0.4025|\n",
    "|K-means-MEMF-3|0.4027|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coverage is very similar for all algorithms. We notice that the baseline's coverage is low comparatively and that the k-means models systematically have better coverage than the other algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5'></a>\n",
    "## Extending the models\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exploration of the our k-means MEMF models suggested that the initial clustering was not as effective as expected. We suspect it has to do with the sparsity of the matrix on which we run the k-means algorithm.\n",
    "\n",
    "We decided to generate **low-dimensional representations of each movie and apply k-means in this lower dimensional space instead of the original one**.\n",
    "\n",
    "We first thought of using Principal Component Analysis to compute these new item vectors. After some thought however we realized that we had access to some condensed item vectors in a framework that was already able to extract valuable information from the data. The vanilla matrix factorization with item and user biases that we used as a baseline to compare our other models was already performing quite well on the testing data and it created low-dimension representations for each movie along the way!\n",
    "\n",
    "We proceeded to define a new model **K-means-MEMF*** which essentially corresponds to **K-means-MEMF-3** with prior dimensionality reduction on movies used only for the generation of clusters and the computation of the membership weights for each movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the new model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us get the data ready for use first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import MEMF_k_means as Mk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hash the data\n",
    "hashed_data = utils.hash_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and validation sets\n",
    "train, test = preprocessing.custom_sampled_train_test_split(hashed_data,\n",
    "                                                            random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the hashing table used to retrieve true ids\n",
    "hashing_table = pd.DataFrame({\"old_item\": train[\"old_item\"],\n",
    "                              \"item\": train[\"item\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create rating vectors\n",
    "y_train = train['rating']\n",
    "y_test =  test['rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters of our model are defined in `K-means-MEMF-exploration.ipynb` ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization on the RMSE of the model's prediction on the validation set let to the following choice of parameters (see `model_tuning.py` for the code used to obtain the RMSE score for the - small - combination of parameters tried):\n",
    "* `n_clusters` = 8\n",
    "* `n_clusters_prediction` = 3\n",
    "* `weight_penalty` = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us instantiate this model and fit it to the training data. Note that we changed `dim_reduc` to \"MF\" so that dimension reduction was carried out before clustering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_star = Mk.MEMF_k_means(n_clusters = 8,\n",
    "                  n_clusters_prediction = 3,\n",
    "                  weight_penalty = 1.,\n",
    "                  fit_all = True,\n",
    "                  dim_reduc = \"MF\",\n",
    "                  tot_users = tot_users, \n",
    "                  tot_items = tot_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22243/22243 [00:44<00:00, 504.09it/s]\n",
      "100%|██████████| 22243/22243 [00:00<00:00, 498396.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10770\n",
      "7692\n",
      "7803\n",
      "7259\n",
      "7254\n",
      "11267\n",
      "7371\n",
      "7313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# create the clusters\n",
    "\n",
    "# reduce dimension using matrix factorization first\n",
    "reduced_sparse_train = M_star.reduce_dimension(train)\n",
    "\n",
    "M_star.compute_membership(hashing_table, reduced_sparse_train)\n",
    "M_star.group_by_cluster(hashing_table)\n",
    "\n",
    "# peek at the distribution of clusters\n",
    "for i in range(len(M_star.clusters_)):\n",
    "    print(len(M_star.clusters_[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this model, each movie belongs to three clusters. The distribution of the number of movies per cluster is much more even than it was with any of the sparse models (explored in `K-means-MEMF-exploration.ipynb`) suggesting that the Matrix Factorization representation of the movies captured some structure and mapped similar movies (in the sense of collaborative filtering not content) into clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_star.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Users with many ratings: users with more than 40 ratings*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20641/20641 [43:04<00:00,  7.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8507171556200355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rmse1 = -utils.predict_popular(M_star, train, test, y_test, item = False, threshold = 40)\n",
    "print(rmse1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The most popular movies : movies with more than 1000 ratings*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29195/29195 [1:05:06<00:00,  7.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8844010530595287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rmse2 = -utils.predict_popular(M_star, train, test, y_test, item = True, threshold = 1000)\n",
    "print(rmse2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The most scarcely rated movies: movies with less than 10 ratings*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4347/4347 [06:26<00:00, 11.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0597605072863787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rmse3 = -utils.predict_popular(M_star, train, test, y_test, item = True, threshold = 10, ascending = True)\n",
    "print(rmse3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RMSE over the whole data is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173374/173374 [5:41:21<00:00,  7.14it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9061918828917068\n"
     ]
    }
   ],
   "source": [
    "rmse_tot = -M_star.score(test, y_test, hashing_table)\n",
    "print(rmse_tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a table summarizing the RMSE of all the k-means models on each segment and over the whole testing set:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  Segment              | K-means-MEMF-1| K-means-MEMF-2 | K-means-MEMF-3 | K-means-MEMF* |\n",
    "|:---------------------:|:-------------:|:--------------:|:--------------:|:-------------:|\n",
    "| Popular movies        | 0.8961        | 0.9176         | 0.8854         |**0.8844**         |\n",
    "| Scarcely rated movies | 1.2192        | 1.1512         | 1.2173         |**1.0598**         |\n",
    "| Active users          | 0.8819        | 0.9226         | 0.8634         |**0.8507**         |\n",
    "| Overall               | 0.9422        | 0.9493         | 0.9185         |**0.9062**         |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new model outperforms all the others on all segments and overall. It does not perform significantly better on popular movies than model 3 however, suggesting that sparsity was not so much of an obstacle for those (and indeed the movies we categorized as \"popular\" had at least 1000 ratings).\n",
    "\n",
    "The new model does significantly better on scarcely rated movies and active users to a lesser extent. Its low-dimensional representation of the movies before clustering extracts the valuable information and structure from those sparse movie vectors (less than 10 ratings) which allows for better performance downstream.\n",
    "\n",
    "Overall accuracy is also much better than the previous k-means models'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the new model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next figure shows the evolution of the RMSE for our final model with different number of clusters, as well as the RMSE for the three other non-k-means based models (the values of RMSE obtained are documented in `evaluation.py` as well as reproductible code):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"figures/rmse.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, it is striking how our model outperforms the other non-k-means models across the span of number of clusters tried. It reaches an RMSE of 0.9062 for 8 clusters which seems to be a - local? - minimum, for the value sof all the other fixed parameters. We are confident that with more computational resources and time dedicated to tuning, the RMSE for the final model could be further decreased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NDCG\n",
    "\n",
    "*TODO : REPORT NDCG OF THE FINAL MODEL AND COMPARE WITH OTHERS*\n",
    "\n",
    "#### Diversity\n",
    "\n",
    "*TODO : REPORT DIVERSITY OF THE FINAL MODEL AND COMPARE WITH OTHERS*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculated coverage of the new model is `0.4036`.\n",
    "\n",
    "| Models | Coverage |\n",
    "|:----:|:----:|\n",
    "|Baseline|0.3990|\n",
    "|Matrix Factorization|0.4012|\n",
    "|Genre-based MEMF|0.4009|\n",
    "|K-means-MEMF*|**0.4036**|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not only has the accuracy increased with the new model, it also seems to exploit more of the catalog in order to make its recommendations than any of the other models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6'></a>\n",
    "## Conclusion\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TODO : PARAGRAPHE SUR LES BENEFICES DE DEPLOYER LE K-MEANS MEMF EN TERMES DE COMPLEXITY, PHASE OFFLINE/ONLINE ET COMMENTAIRE SUR LE FAIT QUE LA MF NOUS A DONNE UNE REPRESENTATION LOW DIMENSION EXPLOITABLE ET QU ON PEUT ENVISAGER SE SERVIR DE CETTE REPRESENTATION POUR FAIRE D AUTRES TRUCS CONTENT BASED PAR EXEMPLE*\n",
    "\n",
    "We focused on customer retention rather than getting new customers to stick around and the models have been optimized with this business objective in mind. \n",
    "\n",
    "In order to deploy the models in a business setting, a **switching** strategy seems like a promising option: using a model tailored to handle the cold-start problem better (such as a content-based filtering recommender) for users with few movie ratings and switching to our model once they get a number of ratings - the exact number would have to be determined either as a hyperparameter of this hybrid switching model or decided by some heuristic. We could also very well imagine setting a threshold of movies needed to be rated by a user that depends on the user himself, or rather in the diversity of her existing ratings. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
