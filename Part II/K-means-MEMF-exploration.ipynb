{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we explore the k-means models defined in `Report.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first load the data and carry out a few preprocessing steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary import - helper functions we implemented\n",
    "from lib import preprocessing\n",
    "from lib import utils\n",
    "from lib import MEMF_k_means as Mk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample ~1 M ratings\n",
    "data = preprocessing.sample_data(\"ratings.csv\", random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the total number of ratings\n",
    "tot_ratings = utils.total_ratings(data)\n",
    "# compute the number of users\n",
    "tot_users = utils.unique_users(data)\n",
    "# compute the number of items\n",
    "tot_items = utils.unique_movies(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hash the item and user ids so that the set of unique hashed ids becomes `range(tot_items)` and `range(tot_users)` for more convenient manipulation in matrix factorization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hash the data\n",
    "hashed_data = utils.hash_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and validation sets\n",
    "train, test = preprocessing.custom_sampled_train_test_split(hashed_data,\n",
    "                                                            random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the hashing table used to retrieve true ids\n",
    "hashing_table = pd.DataFrame({\"old_item\": train[\"old_item\"],\n",
    "                              \"item\": train[\"item\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create rating vectors\n",
    "y_train = train['rating']\n",
    "y_test =  test['rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means MEMF with one cluster per movie (K-means-MEMF-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization on the RMSE of the model's prediction on the validation set let to the following choice of number of clusters (see `model_tuning.py` for the code used to obtain the RMSE score for each number of cluster tries):\n",
    "* `n_clusters` = 8\n",
    "\n",
    "The small number of clusters could suggest that this model does not make the most out of dividing the data into clusters and we will try to see if it is indeed the case in the following."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us instantiate this model and fit it to the training data. Then we peek at the distribution of the number of movies per cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1 = Mk.MEMF_k_means(n_clusters = 8,\n",
    "                  tot_users = tot_users, \n",
    "                  tot_items = tot_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22243/22243 [16:15<00:00, 22.79it/s]\n",
      "22243it [00:18, 1197.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "342\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "21895\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# create the clusters\n",
    "\n",
    "# this function for this model only transforms the data into a sparse matrix\n",
    "reduced_sparse_train = M1.reduce_dimension(train)\n",
    "\n",
    "M1.compute_membership(hashing_table, reduced_sparse_train)\n",
    "M1.group_by_cluster(hashing_table)\n",
    "\n",
    "# peek at the distribution of clusters\n",
    "for i in range(len(M1.clusters_)):\n",
    "    print(len(M1.clusters_[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This results suggests that the clustering phase did poorly. Looking at this we thought that there must be some outliers that create their own clusters systematically. But upon closer inspection, by removing those movies and reconducting the clustering to see if the distribution would become more even across the clusters, it turned out to still be as imbalanced. We believe the imbalance is due to the high sparsity of the ratings of movies that leads to considerably different movie vectors and always leads to better clustering results by isolating a few in their own clusters. \n",
    "\n",
    "**We will address this when extending our models at a later stage**.\n",
    "\n",
    "We now fit the model to the entire training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see how our model performs on different segments. We will compare the RMSE for different groups and the RMSE on the whole data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Users with many ratings: users with more than 40 ratings*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20641/20641 [13:10<00:00, 26.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8826976685021714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rmse1 = -utils.predict_popular(M1, train, test, y_test, item = False, threshold = 40)\n",
    "print(rmse1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The most popular movies : movies with more than 1000 ratings*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29195/29195 [12:48<00:00, 36.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8957380139400553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rmse2 = -utils.predict_popular(M1, train, test, y_test, item = True, threshold = 1000)\n",
    "print(rmse2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The most scarcely rated movies: movies with less than 10 ratings*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4347/4347 [03:13<00:00, 22.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2206227176643751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rmse3 = -utils.predict_popular(M1, train, test, y_test, item = True, threshold = 10, ascending = True)\n",
    "print(rmse3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RMSE over the whole data is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173374/173374 [1:33:04<00:00, 31.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9432428841405675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rmse_tot = -M1.score(test, y_test, hashing_table)\n",
    "print(rmse_tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the model performs better on users and items for which a lot of ground-truth training data is available. It does much more poorly on rare movies. We will keep these results in mind to compare with the other models we explore below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means MEMF with one main cluster per movie and weighted biases (K-means-MEMF-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters of this model are the following:\n",
    "* `n_clusters`: the number of movie clusters (`k`)\n",
    "* `n_clusters_prediction`: the number of closest clusters considered in the prediction weighted sum (`k'` in the discussion of the model definition in `Report.ipynb`)\n",
    "* `weight_penalty`: the parameter of the weight function used to penalize irrelevant clusters ($\\lambda$ in the discussion of the model definition in `Report.ipynb`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization on the RMSE of the model's prediction on the validation set let to the following choice of parameters (see `model_tuning.py` for the code used to obtain the RMSE score for the - small - combination of parameters tried):\n",
    "* `n_clusters` = 12\n",
    "* `n_clusters_prediction` = 2\n",
    "* `weight_penalty` = 1.\n",
    "\n",
    "This model seemed to perform better with a larger number of cluster than the previous one. It still remains very small compared to the number of movies (close to 20,000). The number of closest clusters used in the prediction seems reasonable. When thinking of genres for example, it would be seem reasonable to use three genres to determine the ratings for a movie - although we don't know yet if our clusters here correspond to something genre-like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us instantiate this model and fit it to the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "M2 = Mk.MEMF_k_means(n_clusters = 12,\n",
    "                  n_clusters_prediction = 2,\n",
    "                  weight_penalty = 1.,\n",
    "                  tot_users = tot_users, \n",
    "                  tot_items = tot_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22243/22243 [27:02<00:00, 12.93it/s]\n",
      "22243it [00:21, 1020.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "22232\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# create the clusters\n",
    "\n",
    "# this function for this model only transforms the data into a sparse matrix\n",
    "reduced_sparse_train = M2.reduce_dimension(train)\n",
    "\n",
    "M2.compute_membership(hashing_table, reduced_sparse_train)\n",
    "M2.group_by_cluster(hashing_table)\n",
    "\n",
    "# peek at the distribution of clusters\n",
    "for i in range(len(M2.clusters_)):\n",
    "    print(len(M2.clusters_[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The distribution of movies per cluster clearly demonstrates that this model does not leverage clustering at all: there is clearly something fundamentally wrong with how we cluster movies. We believe the sparsity of the matrix with the addition of  numerous outliers really prevents a useful fragmentation of movies into cluster. This is something we address when extending the model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction score should somehow differ from basic matrix factorization nevertheless because the two nearest clusters are used in the predictions: meaning that eleven or less movies impact all the other ratings (only one movie per cluster for those eleven clusters) through user biases on these movies. This does not seem like a good idea but let us see of the model performs nevertheless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "M2.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Users with many ratings: users with more than 40 ratings*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20641/20641 [18:34<00:00, 18.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.922616505417432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rmse1 = -utils.predict_popular(M2, train, test, y_test, item = False, threshold = 40)\n",
    "print(rmse1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The most popular movies : movies with more than 1000 ratings*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29195/29195 [26:10<00:00, 19.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9176434575082244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rmse2 = -utils.predict_popular(M2, train, test, y_test, item = True, threshold = 1000)\n",
    "print(rmse2)\n",
    "# 0.9189"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The most scarcely rated movies: movies with less than 10 ratings*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4347/4347 [04:18<00:00, 16.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.151220562694912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rmse3 = -utils.predict_popular(M2, train, test, y_test, item = True, threshold = 10, ascending = True)\n",
    "print(rmse3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RMSE over the whole data is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173374/173374 [1:59:10<00:00, 24.32it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9493229192226168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rmse_tot = -M2.score(test, y_test, hashing_table)\n",
    "print(rmse_tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a table summarizing the RMSE of the two models on each segment and over the whole testing set:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  Segment              | K-means-MEMF-1| K-means-MEMF-2 |\n",
    "|:---------------------:|:-------------:|:--------------:|\n",
    "| Popular movies        | **0.8957**        | 0.9176         |\n",
    "| Scarcely rated movies | 1.2206        | **1.1512**         |\n",
    "| Active users          | **0.8827**        | 0.9226         |\n",
    "| Overall               | **0.9432**        | 0.9493         |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second model performs better than the first one of scarcely rated movies. It might be an artefact of adjustements using second clusters that benefits scarcely rated movies (especially the outliers that belong to a cluster of their own) but not the other movies tremendously.\n",
    "\n",
    "The first model performs better on all other segments and overall (although not very significantly overall)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means MEMF with weighted predictions (K-means-MEMF-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters for this model are the same as the previous one. We just have to set the boolean parameter `fit_all` from its default `False` to `True` to make sure it includes movies in all their closest clusters' models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization on the RMSE of the model's prediction on the validation set let to the following choice of parameters (see `model_tuning.py` for the code used to obtain the RMSE score for the - small - combination of parameters tried):\n",
    "* `n_clusters` = 8\n",
    "* `n_clusters_prediction` = 3\n",
    "* `weight_penalty` = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us instantiate this model and fit it to the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "M3 = Mk.MEMF_k_means(n_clusters = 8,\n",
    "                  n_clusters_prediction = 3,\n",
    "                  weight_penalty = 1.,\n",
    "                  fit_all = True,\n",
    "                  tot_users = tot_users, \n",
    "                  tot_items = tot_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22243/22243 [20:35<00:00, 18.01it/s]\n",
      "100%|██████████| 22243/22243 [00:00<00:00, 487210.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# create the clusters\n",
    "\n",
    "# this function for this model only transforms the data into a sparse matrix\n",
    "reduced_sparse_train = M3.reduce_dimension(train)\n",
    "\n",
    "M3.compute_membership(hashing_table, reduced_sparse_train)\n",
    "M3.group_by_cluster(hashing_table)\n",
    "\n",
    "M3.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Users with many ratings: users with more than 40 ratings*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20641/20641 [55:05<00:00,  5.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8625250124869523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rmse1 = -utils.predict_popular(M3, train, test, y_test, item = False, threshold = 40)\n",
    "print(rmse1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The most popular movies : movies with more than 1000 ratings*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29195/29195 [1:06:50<00:00,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8852002191368674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rmse2 = -utils.predict_popular(M3, train, test, y_test, item = True, threshold = 1000)\n",
    "print(rmse2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The most scarcely rated movies: movies with less than 10 ratings*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4347/4347 [10:59<00:00,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2158495105911074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rmse3 = -utils.predict_popular(M3, train, test, y_test, item = True, threshold = 10, ascending = True)\n",
    "print(rmse3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RMSE over the whole data is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173374/173374 [5:43:44<00:00,  8.74it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9185784269336655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rmse_tot = -M3.score(test, y_test, hashing_table)\n",
    "print(rmse_tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a table summarizing the RMSE of the three k-means models on each segment and over the whole testing set:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  Segment              | K-means-MEMF-1| K-means-MEMF-2 | K-means-MEMF-3 |\n",
    "|:---------------------:|:-------------:|:--------------:|:--------------:|\n",
    "| Popular movies        | 0.8957        | 0.9176         | **0.8852**         |\n",
    "| Scarcely rated movies | 1.2206        | **1.1512**         | 1.2158         |\n",
    "| Active users          | 0.8827        | 0.9226         | **0.8625**         |\n",
    "| Overall               | 0.9432        | 0.9493         | **0.9186**         |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third model is the most efficient in terms of accuracy (RMSE). Its overall performance beats the others quite significantly.\n",
    "\n",
    "It seems that model 3 does not improve predictions from model 1 on scarcely rated movies significantly. This suggest that the fault lies in the sparsity of the data itself and that it might be very hard to significantly improve performance on those movies with a strong risk of overfitting over the little ratings.\n",
    "\n",
    "The models perform very well on active users compared to overall performance, which is comforting in that those users are amongst those we wish to target with this recommender system born from an incentive of customer retention. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
